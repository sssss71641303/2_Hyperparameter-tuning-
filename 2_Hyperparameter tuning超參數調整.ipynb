{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/machine-learning-pipelines/intro-to-pipelines/aml-pipelines-parameter-tuning-with-hyperdrive.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用HyperDriveStep的Azure機器學習管道\n",
    "\n",
    "\n",
    "\n",
    "## Azure機器學習和管道SDK特定的導入\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.57\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import urllib\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.core.datastore import Datastore\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "from azureml.data.data_reference import DataReference\n",
    "from azureml.pipeline.steps import HyperDriveStep\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\n",
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.train.hyperdrive import *\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化工作區\n",
    "\n",
    "從持續配置初始化工作區object。 如果使用的是Azure機器學習Notebook VM，則一切就緒。 否則，請確保配置文件位於。\\ config.json中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code BSVP4RQGE to authenticate.\n",
      "Interactive authentication successfully completed.\n",
      "Workspace not accessible. Change your parameters or create a new workspace below\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "subscription_id = \"yoursubscription_id\"\n",
    "resource_group = \"test20191105\"\n",
    "workspace_name = \"test1106ws\"\n",
    "workspace_region = \"eastus2\"\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from azureml.core import Workspace\n",
    "\n",
    "try:\n",
    "    ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "    # write the details of the workspace to a configuration file to the notebook library\n",
    "    ws.write_config()\n",
    "   \n",
    "    print(\"Workspace configuration succeeded. Skip the workspace creation steps below\")\n",
    "except:\n",
    "    print(\"Workspace not accessible. Change your parameters or create a new workspace below\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = InteractiveLoginAuthentication(tenant_id = 'yourtenant_id')\n",
    "ws = Workspace.from_config(auth = auth)\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立Azure ML實驗\n",
    "創建一個名為“ tf-mnist”的實驗和一個用於存放訓練腳本的文件夾。 腳本運行將記錄在Azure實驗中\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_folder = './tf-mnist'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "\n",
    "exp = Experiment(workspace=ws, name='tf-mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下載MNIST數據集\n",
    "為了訓練MNIST數據集，首先需要直接從Yan LeCun的網站下載它，並將其保存在本地的“ data”文件夾中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/mnist/test-labels.gz', <http.client.HTTPMessage at 0x7f2971900358>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs('./data/mnist', exist_ok=True)\n",
    "\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', filename = './data/mnist/train-images.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', filename = './data/mnist/train-labels.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', filename = './data/mnist/test-images.gz')\n",
    "urllib.request.urlretrieve('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', filename = './data/mnist/test-labels.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將MNIST數據集上傳到Blob數據存儲區\n",
    "數據存儲區是可以存儲數據的地方，然後可以通過將數據裝入或複製到計算目標使Run可以訪問它。 在下一步中，我們將使用Azure Blob存儲並將培訓和測試集上傳到Azure Blob數據存儲中，然後將其安裝在Batch AI群集中進行培訓。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 4 files\n",
      "Uploading ./data/mnist/test-images.gz\n",
      "Uploading ./data/mnist/test-labels.gz\n",
      "Uploading ./data/mnist/train-images.gz\n",
      "Uploading ./data/mnist/train-labels.gz\n",
      "Uploaded ./data/mnist/train-labels.gz, 1 files out of an estimated total of 4\n",
      "Uploaded ./data/mnist/test-labels.gz, 2 files out of an estimated total of 4\n",
      "Uploaded ./data/mnist/test-images.gz, 3 files out of an estimated total of 4\n",
      "Uploaded ./data/mnist/train-images.gz, 4 files out of an estimated total of 4\n",
      "Uploaded 4 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_5673bdf244224f82a9304441c6f83d90"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir='./data/mnist', target_path='mnist', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取回或創建Azure機器學習計算\n",
    "Azure機器學習計算是一項用於配置和管理Azure虛擬機群集以運行機器學習工作負載的服務。 讓我們獲取當前工作空間中的默認Azure機器學習計算。 然後，我們將在此計算目標上運行訓練腳本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cpucluster\n"
     ]
    }
   ],
   "source": [
    "#compute_target = ws.get_default_compute_target(\"C\")\n",
    "cpu_cluster_name = \"cpucluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print(\"Found existing cpucluster\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new cpucluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將訓練文件複製到腳本文件夾中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./tf-mnist/utils.py'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the training logic is in the tf_mnist.py file.\n",
    "shutil.copy('./tf_mnist.py', script_folder)\n",
    "\n",
    "# the utils.py just helps loading data from the downloaded MNIST dataset into numpy arrays.\n",
    "shutil.copy('./utils.py', script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立 TensorFlow 估算器\n",
    "構造一個“ azureml.train.dnn.TensorFlow”估計器對象，使用Batch AI集群作為計算目標，並將數據存儲的安裝點作為參數傳遞給訓練代碼。\n",
    "TensorFlow估算器提供了一種在計算目標上啟動TensorFlow訓練作業的簡單方法。 它會自動提供一個安裝了TensorFlow的docker映像-如果需要其他pip或conda軟件包，則可以通過`pip_packages`和`conda_packages`參數傳入它們的名稱，並將它們包含在生成的docker中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - framework_version is not specified, defaulting to version 1.13.\n"
     ]
    }
   ],
   "source": [
    "est = TensorFlow(source_directory=script_folder,                 \n",
    "                 compute_target=compute_target,\n",
    "                 entry_script='tf_mnist.py', \n",
    "                 use_gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 智慧超參數調整\n",
    "已經用一組超參數訓練了模型，現在讓我們來說明如何通過在集群上啟動多個運行來進行超參數調整。 首先，讓我們使用隨機採樣定義參數空間。\n",
    "\n",
    "在此示例中，我們將使用隨機採樣來嘗試不同的超參數配置集，以最大程度地提高我們的主要指標，最佳驗證精度（validation_acc）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "        '--batch-size': choice(25, 50, 100),\n",
    "        '--first-layer-neurons': choice(10, 50, 200, 300, 500),\n",
    "        '--second-layer-neurons': choice(10, 50, 200, 500),\n",
    "        '--learning-rate': loguniform(-6, -1)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定義一個早期終止策略。\n",
    "“BanditPolicy”基本上聲明每2次迭代檢查一次作業。 如果主要指標（稍後定義）超出了前10％的範圍，則Azure ML終止作業。 這使我們免於繼續探索沒有顯示出幫助實現目標指標的希望的超參數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_termination_policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "配置運行配置對象，並指定在訓練運行中記錄的主要指標validation_acc。 如果返回訪問培訓腳本，則會注意到在每個時期（完整的批次設置）之後都記錄了該值。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hd_config = HyperDriveConfig(estimator=est, \n",
    "                             hyperparameter_sampling=ps,\n",
    "                             policy=early_termination_policy,\n",
    "                             primary_metric_name='validation_acc', \n",
    "                             primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                             max_total_runs=1,\n",
    "                             max_concurrent_runs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 添加HyperDrive作為管道的步驟\n",
    "\n",
    "為hyperdrive步驟的輸入設置數據參考"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = DataReference(\n",
    "    datastore=ds,\n",
    "    data_reference_name=\"mnist_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperDriveStep\n",
    "HyperDriveStep可作為管道中的步驟用於運行HyperDrive作業。\n",
    "-名稱：步驟名稱\n",
    "-hyperdrive_config： HyperDriveConfig，它定義了此HyperDrive運行的配置\n",
    "-estimator_entry_script_arguments：估計器輸入腳本的命令行參數列表\n",
    "-inputs：輸入端口綁定列表\n",
    "-輸出：輸出端口綁定列表\n",
    "-metrics_output：可選值，用於指定將HyperDrive運行指標存儲為JSON文件的位置\n",
    "-allow_reuse：是否允許重用\n",
    "-版本：版本\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_output_name = 'metrics_output'\n",
    "metirics_data = PipelineData(name='metrics_data',\n",
    "                             datastore=ds,\n",
    "                             pipeline_output_name=metrics_output_name)\n",
    "\n",
    "hd_step = HyperDriveStep(\n",
    "    name=\"hyperdrive_module\",\n",
    "    hyperdrive_config=hd_config,\n",
    "    estimator_entry_script_arguments=['--data-folder', data_folder],\n",
    "    inputs=[data_folder],\n",
    "    metrics_output=metirics_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step hyperdrive_module [ef6a87db][8220afe4-5eb4-4edc-8e0e-f35278004015], (This step is eligible to reuse a previous run's output)\n",
      "Using data reference mnist_data for StepId [8d91f553][6b6e635c-45c9-4f24-a7ec-3afba465fd32], (Consumers of this data are eligible to reuse prior runs.)\n",
      "Submitted pipeline run: 0669da49-2c05-4eae-93b2-507cdb282df6\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(workspace=ws, steps=[hd_step])\n",
    "pipeline_run = Experiment(ws, 'Hyperdrive_Test').submit(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 等待此管道運行完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 0669da49-2c05-4eae-93b2-507cdb282df6\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/f01533c9-b5ce-48c8-8ff4-9f472eb56574/resourceGroups/test20191105/providers/Microsoft.MachineLearningServices/workspaces/test1106ws/experiments/Hyperdrive_Test/runs/0669da49-2c05-4eae-93b2-507cdb282df6\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '0669da49-2c05-4eae-93b2-507cdb282df6', 'status': 'Completed', 'startTimeUtc': '2019-11-07T04:46:10.020454Z', 'endTimeUtc': '2019-11-07T04:56:34.35419Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': None, 'runType': 'HTTP', 'azureml.parameters': '{}'}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://test1106ws4305527614.blob.core.windows.net/azureml/ExperimentRun/dcid.0669da49-2c05-4eae-93b2-507cdb282df6/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=Ha3nnCxoASldfFi8p3OnQ1yKxU7BExveB0XXOf48B5c%3D&st=2019-11-07T04%3A52%3A12Z&se=2019-11-07T13%3A02%3A12Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://test1106ws4305527614.blob.core.windows.net/azureml/ExperimentRun/dcid.0669da49-2c05-4eae-93b2-507cdb282df6/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=0sOhzxzEjgLaGP08F20qA0pWECIJEi9ZWwfVsaDT5lI%3D&st=2019-11-07T04%3A52%3A12Z&se=2019-11-07T13%3A02%3A12Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://test1106ws4305527614.blob.core.windows.net/azureml/ExperimentRun/dcid.0669da49-2c05-4eae-93b2-507cdb282df6/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=UERpbfOi3%2FwyJJJcIRzw8YiudtbAYEAgpcCRYsXV3Nc%3D&st=2019-11-07T04%3A52%3A12Z&se=2019-11-07T13%3A02%3A12Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the metrics\n",
    "Outputs of above run can be used as inputs of other steps in pipeline. In this tutorial, we will show the result metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading azureml/ad8dd174-a73d-4004-b519-6b6c0c988211/metrics_data\n",
      "Downloaded azureml/ad8dd174-a73d-4004-b519-6b6c0c988211/metrics_data, 1 files out of an estimated total of 1\n"
     ]
    }
   ],
   "source": [
    "metrics_output = pipeline_run.get_pipeline_output(metrics_output_name)\n",
    "num_file_downloaded = metrics_output.download('.', show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperdrive_Test_1573101975911402_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>final_acc</th>\n",
       "      <td>[0.9742000102996826]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_acc</th>\n",
       "      <td>[0.9900000095367432, 0.9800000190734863, 1, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation_acc</th>\n",
       "      <td>[0.9463000297546387, 0.9560999870300293, 0.966...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Hyperdrive_Test_1573101975911402_0\n",
       "final_acc                                    [0.9742000102996826]\n",
       "training_acc    [0.9900000095367432, 0.9800000190734863, 1, 0....\n",
       "validation_acc  [0.9463000297546387, 0.9560999870300293, 0.966..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "with open(metrics_output._path_on_datastore) as f:  \n",
    "    metrics_output_result = f.read()\n",
    "    \n",
    "deserialized_metrics_output = json.loads(metrics_output_result)\n",
    "df = pd.DataFrame(deserialized_metrics_output)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "sonnyp"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
